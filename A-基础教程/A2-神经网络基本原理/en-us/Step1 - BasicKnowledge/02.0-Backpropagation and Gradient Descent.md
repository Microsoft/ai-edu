<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

# Chapter 2 Three Basic Concepts in Neural Networks

## 2.0 Understand three concepts in a simple way

These three concepts are backpropagation, gradient descent, and loss function.

**this change is made by Jasmine **


The basic idea of training in neural networks is first to guess a result, called the predicted result $a$. Check the difference between this expected result and the real result $y$ in the pre-marked training set. Then try again, but this time it is not a "guessing", but an approach to the right direction with an adjusted strategy. Repeat this procedure many times until we have $|a-y|\rightarrow 0$, which means that the difference between the predicted result and the real result is minimal, and then end training. 

We call "guess" initialization in neural network training, which can be random or given an initial value based on previous experience. Even "guessing" is technical.

These three concepts are closely linked, and when you talk about one, you will involve the others. Since the loss function has relatively large content, we will introduce it in detail in the next chapter.

Here are a few examples to illustrate these three concepts intuitively.

### 2.0.1 Example 1: Guess the number

A and B play a game of guessing numbers. The range of numbers is $[1,50]$:

A: I'm going to guess 5

B: Too small

A: 50

B: It's a little big

A: 30

B: Small

......

In this game:

- Purpose: B thinks of a number at random, and A needs to guess it.
- Initialization: A guesses 5;
- Forward calculation: A guesses the new number each time;
- Loss function: B compares the number guessed by A with the number in his mind and comes to the conclusion that it is "bigger" or "smaller";
- Backpropagation: B tells A "big" or "small";
- Gradient descent: A adjusts the guess value for the next round according to the meaning in B's feedback.

What is the loss function here? It's just "too small", "a bit big", which is very imprecise! This "so-called" loss function gives two pieces of information:

1. Direction: bigger or smaller
2. Degree: "too", "a little bit", but very vague

### 2.0.2 Example 2: Black box

Suppose there is a black box, as shown in Figure 2-1.

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/blackbox.png" />

Figure 2-1 Black box

We can only see the input and output values, but not the inside of the black box. When the input is 1, the output is 2.334, and the black box gives a message: I need the output value to be 4. Then we try to input 2, and the output becomes 5.332, which is much larger than 4. Then our first loss value is $2.334-4=-1.666$, and our second loss value is $5.332-4=1.332$.

Here, our loss function is a simple subtraction, subtracting the target value from the actual value, but it can tell you two information: 1) the direction, whether it is larger or smaller; 2) the difference, 0.1 or 1.1. All these give us the basis for the next guess.

- Purpose: to guess an input value so that the output of the black box is 4;
- Initialization: input 1;
- Forward calculation: the mathematical logic inside the black box;
- Loss function: at the output, subtract four from the output value;
- Backpropagation: tell the guesser the difference;
- Gradient descent: At the input, according to the difference, determine the next guess value.

### 2.0.3 Example 3: Target Shooting

Xiao Ming took a rifle and shot a target 100 meters away. This rifle does not have a front sight, or there is a problem with the front sight, or Xiao Ming's eyes are not good enough to see the target, or it is foggy, or windy, or the lateral gravitational field is abnormal due to the influence of Jupiter..... . Anyway, there are all kinds of distractions.

After the first test shot, Xiao Ming pulled back the target and took a look. So in the second test, Xiao Ming consciously shifted the gun a few millimeters to the right and then checked the bullet point on the target. Repeat this procedure several times, and Xiao Ming will master the temper of this rifle. Figure 2-2 shows Xiao Ming's 5 test shots.

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/target1.png" width="500" ch="500" />

Figure 2-2 The bullet point record of shooting

In supervised learning, the difference between the neural network output and the expected output needs to be measured. This error function should reflect a quantized degree of inconsistency between the current network output and the actual results. That is to say, the larger the function value is, the less accurate the outcome predicted by the model will be.

In this example, Xiao Ming's goal is to hit the center of the target. The outermost circle is 1 point. The more you go to the center of the target, the higher the score, like 2, 3, 4 points, and 10 points for hitting the bullseye.

- The gap between the bullet point and the bullseye of each test shot is called the error, which can be represented by an error function, such as the absolute value of the gap, as shown in the red line in the figure.
- Xiao Ming shot a total of five times, which means five times of iterations/training.
- After each shot, the process of pulling the target back to see the impact point and then adjusting the shooting angle for the next time is called backpropagation. Note that there is an essential difference between pulling the target back and looking at it and running to the front to see the target. The latter is life-threatening because there might be other shooters out there. In the mathematical concept, an inappropriate analogy is that when you run in front of a target and look at it, it's called forward differentiation; Pulling the target back to look at it is called reverse differentiation.
- The value and direction of each adjustment angle are called gradient. For example, adjust 1 mm to the right or 2 mm to the bottom left, as shown in the green vector line.

The pattern in the figure above is to fire only one bullet at a time, which means the number of samples per training is one. In the actual neural network training, we usually need multiple samples to do batch training to avoid the error caused by the sampling of a single sample itself. In this example, multiple samples can be described as a burst of shots, assuming that three bullets can be fired in succession at a time, each with a similar degree of dispersion, as shown in Figure 2-3.

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/target2.png" width="600" ch="500" />

Figure 2-3 Record of bursts of bullets

- If three bullets are fired in succession, we divide the sum of the difference between the impact point of three bullets and the bullseye by three and call it "loss", which can be represented by a loss function. 

What is the difference between the result of each shot of Xiao Ming and the target? In this example, if measured by score, it means that Xiao Ming's feedback results range from 9 points to 8 points, to 2 points, to 1 point, to 0 points. This is a way to express the gap between Xiao Ming's shooting and the target with a quantitative result. That is the role of the error function. Because there is only one sample at a time, the term error function is used here. If there are multiple samples at a time, it's called a loss function.

Shooting is not that simple. If it is a long-range sniper, air resistance and wind speed must also be considered. In the neural network, air resistance and wind speed can correspond to a hidden layer concept.

In this example:

- Purpose: to hit the bullseye;
- Initialization: take a shot at will, as long as you can hit the target, but remember the posture of the rifle at that time;
- Forward calculation: let the bullet fly for a while and hit the target;
-Loss function: number of rings, deviation angle;
- Backpropagation: pull the target back to see;
- Gradient descent: adjust the shooting angle of the rifle according to the deviation this time.

The loss function is described as follows:

1. shoot at 1st ring, 45 degrees to the upper left;
2. shoot at 6th ring, 15 degrees to the upper left;
3. shoot at 7th ring, left;
4. shoot at 8th ring, 15 degrees to the lower left;
5. shoot at the bullseye.

The loss function here also has two pieces of information:

1. Distance;
2. Direction.

**So, the gradient is a vector!** It should tell us both the direction and the value.

### 2.0.4 The real play of the black box

The above three examples are relatively simple and easy to understand. Let's ask the black box out again: the real meaning of the black box is not to guess what the input is, and the output will be 4. Its practical significance is: we have to crack this black box! Therefore, we will have the following cracking process:

1. Record all input and output values, as shown in Table 2-1.

Table 2-1 Sample data table

|Sample ID|Input (eigenvalue)|Output (label)|
|:---:|--|--|
|1|1|2.21|
|2|1.1|2.431|
|3|1.2|2.652|
|4|2|4.42|

2. Build a neural network and give the initial weight value. Let us first assume that the logic of this black box is: $z = x + x^2$;
3. Input 1, and the output is 2 according to $z=x + x^2$, and the actual output value is 2.21, the error value is $2-2.21=-0.21$, which is small;
4. Adjust the weight value, like $z=1.5x+x^2$, and then input 1.1, the output obtained is 2.86, the actual output is 2.431, and the error value is $2.86-2.431=0.429$, which is large;
5. Adjust the weight value, such as $z=1.2x+x^2$, then input 1.2...
6. Adjust the weight value, and then input 2...
7. Traverse all the samples once and calculate the average loss function value;
8. Repeat the process of 3, 4, 5, 6 until the loss function value is less than an indicator, such as $0.001$. We can think that the network is trained and the black box is "cracked", but it is actually copied. Because the neural network cannot get the real function body in the black box, but only an approximate simulation.

From the above process, we can see that if the error value is positive, we will reduce the weight; if the error value is negative, we will increase the weight.

### 2.0.5 Summary
Briefly summarize the basic working principles of backpropagation and gradient descent:

1. Initialization;
2. Forward calculation
3. The loss function provides us with a method to calculate the loss;
4. Gradient descent is based on the loss function and approaches the point with the smallest loss, thus guiding the direction of network weight adjustment.
5. Backpropagation passes the loss value back to each layer of the neural network so that each layer adjusts the weight according to the loss value in the reverse direction;
6. Go to 2 until the accuracy is good enough (for example, the loss function value is less than 0.001).