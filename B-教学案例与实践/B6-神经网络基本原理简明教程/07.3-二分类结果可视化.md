Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 二分类结果可视化

木头：老师，我们虽然得到了结果，但都是一些神秘的数字，我们如何知道它们是正确还是错误的呢？

铁柱：后面我们会讲到，一般我们会把样本分成训练集、测试集，用测试集来验证训练结果的正确性。本例我们没有这样做，因为我没有更加好的手段：可视化的训练结果会对我们的调试、学习有巨大的帮助。

木头：那么下面的这几个关于W,B数字如何可视化呢？

```
W= [[-18.18569771   6.49279869]]
B= [[7.77920305]]
```

铁柱：这是一个线性二分类问题，所以如果我们能够根据以这个训练结果，在图上画出一条直线来分割两个区域，是不是就很直观了呢？

木头：是滴~

铁柱：别酸了！你把正向计算公式写一下。

木头：好滴~......好的......

$$
Z = W \cdot X+B=w_{1} \cdot x_1 + w_{2} \cdot x_2 + b
$$
$$
A=Sigmoid(Z)
$$

铁柱：当A大于0.5时，属于汉，当A小于0.5时，属于楚。那么A=0.5时，就是边界啦！

木头：哦！那我再写一下公式。
$$A = 0.5, 相当于Z=0$$
$$Z = W \cdot X+B=w_{1} \cdot x_1 + w_{2} \cdot x_2 + b = 0$$

铁柱：再把x2留在等式左侧，其它的挪到右侧去，就可以得到一条直线的方程了。

$$w_{2} \cdot x_2 = -w_{1} \cdot x_1 - b$$
$$x2 = -{w_1 \over w_2}x_1 - {b \over w_2} \tag{1}$$

好了，这就是标准的直线方程$y=ax+b$的形式了。这个公式等同于二分类原理中的公式14，15。

木头：好，我用Python代码实现一下。

先在程序运行前，展示一下样本数据：

```Python
def ShowData(X,Y):
    for i in range(X.shape[1]):
        if Y[0,i] == 0:
            plt.plot(X[0,i], X[1,i], '.', c='r')
        elif Y[0,i] == 1:
            plt.plot(X[0,i], X[1,i], 'x', c='g')
        # end if
    # end for
    plt.show()
```

在程序运行后，展示一下结果：

```Python
def ShowResult(X,Y,W,B,xt):
    for i in range(X.shape[1]):
        if Y[0,i] == 0:
            plt.plot(X[0,i], X[1,i], '.', c='r')
        elif Y[0,i] == 1:
            plt.plot(X[0,i], X[1,i], 'x', c='g')
        # end if
    # end for

    w12 = -W[0,0]/W[0,1]
    b12 = -B[0,0]/W[0,1]

    x = np.linspace(0,1,10)
    y = w12 * x + b12
    plt.plot(x,y)

    for i in range(xt.shape[1]):
        plt.plot(xt[0,i], xt[1,i], '^', c='b')

    plt.axis([-0.1,1.1,-0.1,1.1])
    plt.show()
```
上面代码中的计算w12,b12的code就是根据公式1来的，只不过我们的W的定义是(w1, w2)，而python是zero-based，所以:

$$w1 = W[0,0]$$

$$w2 = W[0,1]$$

$$b = B[0,0]$$

简单说，就是把所有下标都减1。再改一下主程序，调用上面两段代码：

```Python
# 主程序
if __name__ == '__main__':
    # SGD, MiniBatch, FullBatch
    method = "SGD"
    # read data
    XData,YData = ReadData(x_data_name, y_data_name)
    X, X_norm = NormalizeData(XData)
    ShowData(XData, YData)
    Y = ToBool(YData)
    W, B = train(method, X, Y, ForwardCalculationBatch, CheckLoss)
    print("W=",W)
    print("B=",B)
    xt = np.array([5,1,6,9,5,5]).reshape(2,3,order='F')
    result, xt_norm = Inference(W,B,X_norm,xt)
    print("result=",result)
    print(np.around(result))
    ShowResult(X,YData,W,B,xt_norm)
```

下图为样本数据：

<img src=".\Images\7\BinaryClassifierData.png">

下图为结果：

<img src=".\Images\7\binary_result.png">

可以看到：
1. 分割线非常准确
2. 三个蓝色三角点是求解问题的三个坐标

需要注意的问题：
1. 我们用归一化前的数据画的第一张图，所以坐标范围是[0,10][0,10]
2. 我们用归一化后的数据画的第二张图，所以坐标范围是[0,1][0,1]
   
代码位置：ch07, BaseClassification.py, level1_BinaryClassification.py, level2_ShowBinaryResult.py