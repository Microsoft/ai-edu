Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  
在这一章，我们将简要介绍一下激活函数，因为在下一章中将要使用激活函数构造神经网络。

- [挤压（饱和）型激活函数](07.1-挤压型激活函数.md)
- [半线性（非饱和）激活函数](07.2-半线性激活函数.md)
- [用双曲正切函数分类](07.3-用双曲正切函数分类.md)
- [实现逻辑与门和或门](07.4-实现逻辑与门和或门.md)

# 激活函数

看神经网络中的一个神经元，为了简化，假设该神经元接受三个输入，分别为$x_1, x_2, x_3$,那么$z=\sum\limits_{i}w_ix_i+b_i$,

<img src=".\Images\1\NeuranCell.png">

激活函数也就是$A=a(Z)$这一步了，他有什么作用呢？主要是给神经网络增加非线性因素，这个问题在第1章《神经网络基本工作原理》中已经讲过了。

激活函数的基本性质：

+ 非线性：线性的激活函数和没有激活函数一样。

+ 可导性：做误差反向传播和梯度下降，必须要保证激活函数的可导性。

+ 单调性：单一的输入会得到单一的输出，较大值的输入得到较大值的输出

在物理试验中使用的继电器，是最初的激活函数的原型：当输入电流大于一个阈值时，会产生足够的磁场，从而打开下一级电源通道，如下图所示：

<img src=".\Images\8\step.png">

用到神经网络中的概念，用‘1’来代表一个神经元被激活，‘0’代表一个神经元未被激活。

这个函数有什么不好的地方呢？主要的一点就是，他的梯度（导数）恒为零（个别点除外)。反向传播公式中，梯度传递用到了链式法则，如果在这样一个连乘的式子其中有一项是零，这样的梯度就会恒为零，是没有办法进行反向传播的。


