Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 常用名词

在各种材料中经常看到的中英文词汇有：误差，偏差，Error，Cost，Loss，损失，代价......意思都差不多，在本系列文章中，使用损失函数和Loss Function这两个词汇，具体的损失函数符号用J()来表示。


**损失**就是所有样本的**误差**的总和，亦即：
$$损失 = \sum^m_{i=1}误差_i$$

在黑盒子的例子中，我们如果说“某个样本的损失”是不对的，只能说“某个样本的误差”，如果我们把神经网络的参数调整到完全满足一个样本的输出误差为0，通常会令其它样本的误差变得更大，这样作为误差之和的损失函数值，就会变得更大。所以，我们通常会在根据某个样本的误差调整权重后，计算一下整体样本的损失函数值，来判定网络是不是已经训练到了可接受的状态。

在上面的例子中，我们使用单个样本进行训练。在批量样本训练中，实际写code时，经常会出现的问题是，忘记用样本误差之和除以样本数量，结果得到了比实际误差大很多的数值，造成网络训练结果波动。

# 机器学习常用损失函数

**符号规则：a是预测值，y是样本标签值，Loss是损失函数值**

- Gold Standard Loss，又称0-1误差（蓝色）
$$
J=\begin{cases} 0 & a=y \\ 1 & a \ne y \end{cases}
$$

- 绝对值损失函数

$$
J = |y-a|
$$

- Hinge Loss，铰链/折页损失函数或最大边界损失函数（红色），主要用于SVM（支持向量机）中

$$
J=max(0,1-y \cdot a), y=\pm 1
$$

- Log Loss，对数损失函数，又叫交叉熵损失函数(cross entropy error)（黄色）

$$
J = -\frac{1}{m} \sum_i^m y_i log(a_i) + (1-y_i)log(1-a_i),  y_i \in \{0,1\}
$$

- Squared Loss，均方差损失函数（黑色）
$$
J=\frac{1}{2m} \sum_i^m (a_i-y_i)^2
$$

- Exponential Loss，指数损失函数（绿色）
$$
J = \frac{1}{m}\sum_i^m e^{-y_i \cdot a_i}
$$



<img src=".\Images\3\error_function.png"/>

以上内容参考了[这篇博客的内容。](http://kubicode.me/2016/04/11/Machine%20Learning/Say-About-Loss-Function/)

# 神经网络中常用的损失函数

- 均方差函数，主要用于回归。详见《3.1-均方差损失函数》

- 交叉熵函数，主要用于分类。详见《3.2-交叉熵损失函数》。

# 损失函数的作用

损失函数的作用，就是计算神经网络每次迭代的前向计算结果与真实值的差距，从而指导下一步的训练向正确的方向进行。

如何使用损失函数呢？具体步骤：
1. 用随机值初始化前向计算公式
2. 代入样本，计算输出的预测值
3. 用损失函数计算预测值和标签值（真实值）的误差
4. 将误差回传，修订前向计算公式
5. goto 2, 直到损失函数值达到一个满意的值就停止迭代

如下图所示：
<img src=".\Images\2\grad2.png" width="600">  

1. 我们先知道了A点的切线的方向，亦即黄色的线，但是不知道长度
2. 我们有步长值η，以及梯度下降公式$X_1 = X_0 – η * dx$
3. 因为$y'_x的导数dx = 2(X-1), η = 0.1, X_0 = 0.2, 于是有X_1 = X_0–0.1*2(X_0-1) = 0.36$，这就等同于我们知道了切线的长度，亦即绿色的线的长度和方向都确定了
4. 然后我们可以画出红色的线（亦即弦线）

所以，弦线在这里面没啥用途，只是表示一个迭代跳跃的动作而已。实际的变化值已经由绿色的线定义好了。

另外一种理解方式如下图所示：
<img src=".\Images\2\gd.png">  
不同的参数组合形成的损失函数值，可以形成一个不规则椭圆，不规则椭圆的圆心位置，是损失值为0的位置，也是我们要逼近的目标。

这个椭圆，类似地图等高线来表示的一个洼地，中心位置比边缘位置要低，通过对损失函数的计算，对损失函数的求导，对网络参数的求导，会带领我们沿着等高线形成的梯子一步步下降，无限逼近中心点。
