Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 线性多分类的神经网络实现  

## 提出问题

我们在上一个二分类问题的基础上，再进一步。除了PM2.5和PM10以外，TSP（总悬浮颗粒物，标签为3）也来和人们捣乱。

|样本序号|1|2|3|4|...|200|
|---|---|----|---|--|--|--|
|温度|0|13|2|24|...|8|
|湿度|55|14|46|58|...|78|
|污染物|1|3|2|3|...|1|

<img src=".\Images\7\MultipleClassifierData.png">

1. PM2.5（可入肺颗粒物，标签为1，蓝色点）
2. PM10（可吸入颗粒物，标签为2，绿色点）
3. TSP（总悬浮颗粒物，标签为3，红色点）

举例来说，当温度是25摄氏度，湿度是40时，处于蓝色点区域，即PM10占比较大。

### 问题，给定温度湿度条件下，预测当前那种污染物占主要比重？
#### 1. 温度=5.1摄氏度，湿度=12.7
#### 2. 温度=25.3摄氏度，湿度=42.1
#### 3. 温度=34.3摄氏度，湿度=82.2

## 问题分析

从图示来看，似乎在三个颜色区间之间有两个比较明显的分界线，而且是直线，即线性可分的。我们如何通过神经网络精确地找到这两条分界线呢？

- 从视觉上判断是线性可分的，所以我们使用单层神经网络即可
- 输入特征是温度和湿度，所以我们在输入层设置两个输入X1=温度值，X2=湿度值
- 最后输出的是三个分类，分别是PM2.5，PM10，TSP，所以输出层有三个神经元

## 定义神经网络结构

这个网络只有输入层和输出层，由于输入层不算在内，所以是一层网络。

<img src=".\Images\7\MultipleClassifierNN.png">

与前面的单层网络不同的是，本图最右侧的输出层还多出来一个Softmax分类函数，这是多分类任务中的标准配置，可以看作是输出层的激活函数，并不单独成为一层。

### 输入层

输入温度(x1)和湿度(x2)两个特征：

$$
X=\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}
$$

### 权重矩阵W1/B1

W权重矩阵的尺寸，可以从后往前看，比如：输出层是3个神经元，输入层是2个特征，则W的尺寸就是3x2。

$$
W=\begin{pmatrix}
w_{11} & w_{12} \\
w_{21} & w_{22} \\
w_{31} & w_{32} 
\end{pmatrix}
$$

B的尺寸是3x1，行数永远和W一样，列数永远是1。

$$
B=\begin{pmatrix}
b_1 \\
b_2 \\
b_3 
\end{pmatrix}
$$

### 输出层

输出层三个神经元，再加上一个Softmax计算，最后有A1,A2,A3三个输出，写作：

$$
Z = \begin{pmatrix}Z1 \\ Z2 \\ Z3 \end{pmatrix},
A = \begin{pmatrix}A1 \\ A2 \\ A3 \end{pmatrix}
$$

其中，$Z=W \cdot X+B，A = Softmax(Z)$

### 样本数据

下载后拷贝到您要运行的Python文件所在的文件夹。

[点击下载训练样本数据X](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/X3.dat)

[点击下载训练标签数据Y](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/Y3.dat)

### 样本特征值

样本数据集中一$X_m$表示第m个样本值，$x_{m,n}$表示第m个样本的第n个特征值。样本数据集中一共有200个数据，每个数据有两个特征：温度和湿度。所以定义矩阵如下：
$$
X = 
\begin{pmatrix}
X_1 & X_2 \dots X_{119}
\end{pmatrix}=
\begin{pmatrix}
x_{1,1} & x_{2,1} \dots x_{119,1} \\
\\
x_{1,2} & x_{2,2} \dots x_{119,2} \\
 \end{pmatrix}
$$
$$
=\begin{pmatrix}
0 & 13 & 2 & 24 & \dots & 8 \\
\\
55 & 14 & 46 & 58 & \dots & 78 \\
 \end{pmatrix}
$$


### 样本标签数据

一般来说，在标记样本时，我们会用1，2，3这样的标记，来指明是哪一类。所以样本数据中是这个样子的：
$$
Y = 
\begin{pmatrix}
Y_1 & Y_2 \dots Y_{200}
\end{pmatrix}=
\begin{pmatrix}1 & 3 & 2 & 3 & \dots & 1\end{pmatrix}
$$

在有Softmax的多分类计算时，我们用下面这种等价的方式，俗称One-Hot，就是在一个向量中只有一个数据是1，其它都是0。
$$
Y = 
\begin{pmatrix}
Y_1 & Y_2 & \dots & Y_m
\end{pmatrix}=
\begin{pmatrix}
y_{1,1} & y_{2,1} \dots y_{200,1} \\
y_{1,2} & y_{2,2} \dots y_{200,2} \\
y_{1,3} & y_{2,3} \dots y_{200,3}
\end{pmatrix}=
\begin{pmatrix}
1 & 0 & 0 & 0 & \dots & 1 \\
0 & 0 & 1 & 0 & \dots & 0 \\
0 & 1 & 0 & 1 & \dots & 0
\end{pmatrix}
$$

OneHot的意思，在这一列数据中，只有一个1，其它都是0。1所在的行数就是这个样本的分类类别。

标签数据对应到每个样本数据上，列对齐，只有(1,0,0)，(0,1,0)，(0,0,1)三种组合，分别表示第一类(PM2.5)、第二类(PM10)和第三类(TSP)污染物占主要比重。当然我们不能排除某一时刻既有PM2.5又有PM10的情况，但两者总有一个占比重大，一个占比重小，所以就指定占比大的那个为1，其余两个为0。



## 代码实现

我们先无耻地从第5章的代码库ch05中，把一些已经写好的函数copy过来，形成一个BaseClassification.py文件，其中会包括神经网络训练的基本过程函数，加载数据，数据的归一化函数，结果显示函数等等。

### 加载数据

基本的加载数据和对样本数据的归一化工作，都可以用前一章的代码来完成，统一集成在BaseClassification.py中了，下面代码中的from BaseClassification import *就是完成了代码引入的工作。但是对于标签数据，需要一个特殊处理。

```Python
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import math
from BaseClassification import *

x_data_name = "Pollution2CategoryX.dat"
y_data_name = "Pollution2CategoryY.dat"

def ToBool(YData):
    num_example = YData.shape[1]
    Y = np.zeros((1, num_example))
    for i in range(num_example):
        if YData[0,i] == 1:     # 第一类的标签设为0
            Y[0,i] = 0
        elif YData[0,i] == 2:   # 第二类的标签设为1
            Y[0,i] = 1
        # end if
    # end for
    return Y
```
遍历标签数据YData中所有记录，设置类别为1的标签为负例0，设置类别为2的标签为正例1。下载的数据中，被标记为1和2，表示第1类和第2类，需要转换成0/1。


### 前向计算

前向计算需要增加分类函数调用：

```Python
def Softmax(Z):
    shift_z = Z - np.max(Z, axis=0)
    exp_z = np.exp(shift_z)
    A = exp_z / np.sum(exp_z, axis=0)
    return A

# 前向计算
def ForwardCalculationBatch(W, B, batch_X):
    Z = np.dot(W, batch_X) + B
    A = Softmax(Z)
    return A
```

### 计算损失函数值

损失函数不再是均方差了，而是交叉熵函数对于多分类的形式。

```Python
def CheckLoss(W, B, X, Y):
    m = X.shape[1]
    A = ForwardCalculationBatch(W,B,X)
    p1 = np.log(A)
    p2 =  np.multiply(Y, p1)
    LOSS = np.sum(-p2) 
    loss = LOSS / m
    return loss
```

### 推理函数

```Python
    xt_normalized = NormalizePredicateData(xt, X_norm)
    A = ForwardCalculationBatch(W,B,xt_normalized)
    r = np.argmax(A,axis=0)+1
    return A, xt_normalized, r
```

最后一个函数np.argmax的作用是比较A里面的几个数据的值，返回最大的那个数据的行数或者列数，0-based。比如A=(1.02,-3,2.2)时，会返回2，因为2.2最大，所以我们再加1，变成1，2，3类。

### 主程序

```Python
# 主程序
if __name__ == '__main__':
    # SGD, MiniBatch, FullBatch
    method = "SGD"
    # read data
    XData,YData = ReadData(x_data_name, y_data_name)
    X, X_norm = NormalizeData(XData)
    ShowData(XData, YData)
    num_category = 3
    Y = ToOneHot(YData, num_category)
    W, B = train(method, X, Y, ForwardCalculationBatch, CheckLoss)

    print("W=",W)
    print("B=",B)
    xt = np.array([5.1,12.7,25.3,42.1,34.3,82.2]).reshape(2,3,order='F')
    a, xt_norm, r = Inference(W,B,X_norm,xt)
    print("Probility=", a)
    print("Result=",r)
```

### 运行结果

```
epoch=99, iteration=180, loss=0.172645
W= 
[[ -0.44305496 -18.00049749]
 [ -2.50537015  17.4041578 ]
 [  2.94842511   0.59633969]]
B= 
[[ 9.05624675]
 [-9.66244417]
 [ 0.60619742]]
Probility= 
[[9.94426055e-01 2.96435767e-02 9.07336981e-08]
 [1.40813131e-06 7.61414860e-03 9.19593052e-01]
 [5.57253689e-03 9.62742275e-01 8.04068571e-02]]
Result= [1 3 2]
```
注意，Probility的结果，对于每个测试样本的结果，是按列看的，即第一列是第一个测试样本的分类结果。

1. 温度=5.1摄氏度，湿度=12.7，概率0.994，第1类
2. 温度=25.3摄氏度，湿度=42.1，概率0.962，第3类
3. 温度=34.3摄氏度，湿度=82.2，概率0.919，第2类


代码位置：ch07, BaseClassification.py, level3_MultipleClassification.py



# 可视化训练结果
```Python
def ShowResult(X,Y,W,B,rangeX,eta,iteration,eps):
    for i in range(X.shape[1]):
        if Y[0,i] == 0 and Y[1,i]==0 and Y[2,i]==1:
            plt.scatter(X[0,i], X[1,i], c='r')
        elif Y[0,i] == 0 and Y[1,i]==1 and Y[2,i]==0:
            plt.scatter(X[0,i], X[1,i], c='b')
        else:
            plt.scatter(X[0,i], X[1,i], c='g')
   
    b12 = (B[1,0] - B[0,0])/(W[0,1] - W[1,1])
    w12 = (W[1,0] - W[0,0])/(W[0,1] - W[1,1])

    b23 = (B[2,0] - B[1,0])/(W[1,1] - W[2,1])
    w23 = (W[2,0] - W[1,0])/(W[1,1] - W[2,1])

    x = np.linspace(0,rangeX,10)
    y = w12 * x + b12
    plt.plot(x,y)

    x = np.linspace(0,rangeX,10)
    y = w23 * x + b23
    plt.plot(x,y)

    title = str.format("eta:{0}, iteration:{1}, eps:{2}", eta, iteration, eps)
    plt.title(title)
    
    plt.xlabel("Temperature")
    plt.ylabel("Humidity")
    plt.show()
```



