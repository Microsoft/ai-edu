Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 搭积木 - 非线性多分类

在第十一章中，我们用一个两层的神经网络，实现了非线性多分类。这次我们来测试一下mini框架对多分类任务的支持。

## 数据

```Python
def LoadData():
    dataReader = DataReader(x_data_name, y_data_name)
    dataReader.ReadData()
    dataReader.Normalize(normalize_x = True, normalize_y = True, to_one_hot = True)
    return dataReader
```
对于本例，由于是分类任务，需要把Y值转成One-hot编码。

## 可视化结果

```Python

```

## 搭建模型

<img src='./Images/14/multiple_classifier.png'/>


```Python
if __name__ == '__main__':
    dataReader = LoadData()
    num_input = dataReader.num_feature
    num_hidden1 = 8
    num_output = 3

    max_epoch = 1000
    batch_size = 10
    learning_rate = 0.1
    eps = 0.06

    params = CParameters(learning_rate, max_epoch, batch_size, eps,
                        LossFunctionName.CrossEntropy3, 
                        InitialMethod.Xavier, 
                        OptimizerName.SGD)

    net = NeuralNet(params)
    fc1 = FcLayer(num_input, num_hidden1, params)
    net.add_layer(fc1, "fc1")
    relu1 = ActivatorLayer(Relu())
    net.add_layer(relu1, "relu1")
    fc2 = FcLayer(num_hidden1, num_output, params)
    net.add_layer(fc2, "fc2")
    softmax1 = ClassificationLayer(Softmax())
    net.add_layer(softmax1, "softmax1")

    net.train(dataReader, checkpoint=10, need_test=False)
    net.ShowLossHistory()
    
    ShowResult(net, params.toString())
    ShowData(dataReader)
```

1. 先构造一个参数集合CParameters，包括：
   1. 学习率=0.1
   2. 最大epoch=1000
   3. 批大小=10
   4. eps停止条件=0.06
   5. 损失函数形态(多分类交叉熵)
   6. 初始化方法(default为Xavier)
   7. 优化器选择default为(SGD)
2. 构造网络NeuralNet，传入参数
3. 构造第一个FC层，指定输入样本特征数量和输出（num_hidden1）神经元个数值，及Relu激活函数
4. 构造第二个FC层，指定输入和输出尺寸
5. 因为是多分类函数，指定Softmax分类函数
6. 开始训练，并传入DataReader实例

net.train()函数是一个阻塞函数，只有当训练完毕后才返回。

# 代码位置

ch14, Level3
