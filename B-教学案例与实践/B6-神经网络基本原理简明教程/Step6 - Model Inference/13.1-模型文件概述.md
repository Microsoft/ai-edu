<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

## 13.1 模型文件概述

上一节中重复使用了保存过的权重矩阵，省去了重新训练的过程，但是不难发现还有一些其它的问题。

比如说，加载权重矩阵之前要先搭建网络，而且要和训练时的网络结构一致。所以，网络结构最好也可以像权重矩阵一样保存下来，在需要使用的时候进行加载。

实际上，几乎所有的训练平台也是这么做的，会把网络结构、权重矩阵等信息保存在文件中，这就是我们常说的模型文件，后面也直接简称为模型。

### 13.1.1 模型文件快问快答

下面我们通过快问快答的形式了解下模型文件。

**1. 为什么需要模型文件？**

如今人工智能发展的越来越快，在图像分析、自然语言处理、语音识别等领域都有着令人惊喜的效果。而模型，可以想象为一个“黑盒”，输入是你需要处理的一张图像，输出是一个它的类别信息或是一些特征，模型文件也因此保存了能完成这一过程的所有重要信息，并且还能用来再次训练、推理等，方便了模型的传播与发展。

**2. 模型文件描述的是什么？**

首先我们需要了解，目前绝大部分的深度学习框架都将整个AI模型的计算过程抽象成数据流图（Data Flow Graphs），用户写的模型构建代码都由框架组建出一个数据流图（也可以简单理解为神经网络的结构），而当程序开始运行时，框架的执行器会根据调度策略依次执行数据流图，完成整个计算。

当有了这个背景知识后，我们很容易想到，为了方便地重用AI模型的计算过程，我们需要将它运行的数据流图、相应的运行参数（Parameters）和训练出来的权重（Weights）保存下来，这就是AI模型文件主要描述的内容。

**3. AI模型的作用是什么？**

以视觉处理为例，人通过眼睛捕获光线，传递给大脑处理，返回图像的一些信息，比如，这是花，是动物。AI模型的作用就相当于大脑的处理，能根据输入的数据给予一定的判断。使用封装好的AI模型，那么设计者只需要考虑把输入的数据处理成合适的格式（类似于感光细胞的作用），然后传递给AI模型（大脑），之后就可以得到一个想要的输出。

**4. 模型文件有哪些类型，TensorFlow和其他框架的有什么区别？**

由于每个深度学习框架都有自己的设计理念和工具链，对数据流图的定义和粒度都不一样，所以每家的AI模型文件都有些区别，几乎不能通用。例如，TensorFlow的Checkpoint Files用Protobuf去保存数据流图，用SSTable去保存权重；Keras用Json表述数据流图而用h5py去保存权重；PyTorch由于是主要聚焦于动态图计算，模型文件甚至只用pickle保存了权重而没有完整的数据流图。

TensorFlow在设计之初，就考虑了从训练、预测、部署等复杂的需求，所以它的数据流图几乎涵盖了整个过程可能涉及到操作，例如初始化、后向求导及优化算法、设备部署（Device Placement）和分布式化、量化压缩等，所以只需要通过TensorFlow的模型文件就能够获取模型完整的运行逻辑，所以很容易迁移到各种平台使用。

**5. 我拿到了别人的一个模型文件，我自己有一些新的数据，就能继续训练AI么？如果不能，还差什么呢？**

训练模型的时候，除了网络架构和权重，还有训练时所使用的各种超参，比如使用的优化器（Optimizer）、批量大小（Batch size）、学习率（Learning rate）、冲量（Momentum）等，这些都会影响我们再训练的效果，需要格外注意。

比如Caffe的记录模型结构的文件会分为`train_val.prototxt`和`inference.prototxt`。首先，`train_val.prototxt`文件是网络结构及训练的配置文件，在训练时使用，而`inference.prototxt`在测试与部署时使用。因此，像网络结构部分，如：name，type，top，input_param等，两个文件都需要用到，在两个文件中都进行了保存；而一些训练部分的参数，如：max_iter（训练集一共要过多少次网络），lr_policy（使用的学习率方法）等，只在训练使用的模型文件中保存。

**6. ONNX文件是什么，如何保存为ONNX文件?**

开放式神经网络交换（Open Neural Network Exchange，简称ONNX）是由微软、FaceBook、亚马逊等多个公司一起推出的，针对机器学习设计的开放式文件格式，可以用来存储训练好的模型。它使得不同的人工智能框架可以采用相同格式存储模型数据并交互。

目前很多机器学习框架都支持ONNX格式，如PyTorch、Caffe2、CNTK、ML.NET、MXNet等，它们都有专门的export_to_onnx方法，通过遍历它们原生的数据流图，转化为ONNX标准的数据流图。而对于TensorFlow这样并不原生支持ONNX的框架，通常会使用图匹配（Graph Matching）的方式转化数据流图。

**7. 转化得来的模型文件有什么信息丢失么？**

由于模型文件仅仅描述了数据流图和权重，并不包含操作符（Op）的具体实现，所以不同框架对于“同名”的操作符理解和实现也会有所不同（例如不同框架的Conv/Pool Padding方式），最终有可能得到不完全一致的推理结果。

**8. 模型文件是如何与应用程序一起工作的？**

应用程序使用模型文件，本质也是要执行模型文件的数据流图。一般有两种方式实现模型文件和应用程序的协作：如果有可以独立执行模型文件的运行时（Runtime），例如系统级别的CoreML、WinML和软件级别的Caffe、DarkNet等，我们就可以在程序中动态链接直接使用；除此以外，我们也可以将数据流图和执行数据流图的程序（一般称为Op Kernel）编译在一起，从而脱离运行时，由于单一模型涉及到的操作有限，这样可以极大减少框架所占用的资源。

在将模型集成到应用程序中前，应该先使用模型查看工具（如Netron等）查看模型的接口、输入输出的格式和对应的范围，然后对程序中传入模型的输入作对应的预处理工作，否则可能无法得到预期的效果。

**9. 如果我本地机器有GPU，那么我在运行推理模型的时候，怎么能利用上本地的资源呢？**

首先需要安装匹配的显卡驱动、CUDA和GPU版的框架，然后根据框架进行代码调整：对于TensorFlow这样能够自动做设备部署（Device Placement）的框架，它会尽量把GPU支持的操作自动分配给GPU计算，不太需要额外的适配；对于PyTorch、MXNet这样不具有自动设备部署功能的框架，可能需要进行一个额外的操作将模型、张量（Tensor）从CPU部署到GPU上。

**10. 模型文件有单元测试来保证质量标准么？**

在机器学习领域，混淆矩阵又称为可能性表格或是错误矩阵。它是一种特定的矩阵，其每一列代表预测值，每一行代表的是实际的类别。它可以用来呈现算法性能的可视化效果，通常被用来显示监督学习的效果（非监督学习通常用匹配矩阵：matching matrix）。混淆矩阵的名字来源于它可以非常容易的表明多个类别是否有混淆，也就是一种类别是否被预测成另一类别。图13-4是混淆矩阵可视化的效果。
  
<img src="../Images/13/QA4.jpg">

图13-4 混淆矩阵可视化

那么我们为什么需要它呢？比如说，程序员们训练了一轮模型，经过测试，该模型在大部分测试样例上表现的很好，但有个别的表现不好。于是经过了对不好的样例的分析，对模型进行调整和重新训练。也许重新训练后在这些特定的例子上准确率已经很高，但是我们无法确认，新的模型是否在原来已经预测很准确的例子上仍然表现良好。这时就引入了混淆矩阵，可以直观的可视化模型的质量。

**11. 如果一个模型文件已经集成到一个应用程序中发布到了很多用户那里， 这时候我们又训练出了一个新的模型，怎么更新众多的应用达到持续开发和持续集成的效果呢？**

如果应用程序是依赖额外的运行来使用模型，只需要更新模型文件就可以了；如果是使用的模型和Kernel编译在一起的方式，就需要重新编译程序。

### 13.1.2 查看模型文件

通过前面的快问快答，我们对模型文件有了一个直观的认识。做一个简单的回忆，模型文件描述了什么？如何把深度学习模型和应用程序结合起来？在这个过中需要注意些什么？

如果全部记住了，那么恭喜你！你已经对神经网络模型有了一个很好的认识了！如果没有，也不要着，下面我们会用一个例子，来分析我们上面提到的模型文件内容。

为了阐述的方便，我们用TensorFlow的Keras封装，快速生成一个简单的模型，这个模型由一个全连接层和一个ReLU激活层组成，其中全连接层在Keras中也叫Dense层。

```python
from tensorflow import keras

inputs = keras.Input(shape=(784,), name='input_data')
dense_result = keras.layers.Dense(10)(inputs)
outputs = keras.layers.ReLU()(dense_result)

model = keras.Model(inputs=inputs, outputs=outputs, name='simple_model')
model.save('simple_model.h5')
```

在这份代码中，首先定义了尺寸为784的输入数据，可以理解为是尺寸为28x28单通道图片，比如MNIST数据集的图片。然后让输入数据经过一层Dense层，设置该层的输出尺寸为10。最后经过一层ReLU激活，得到最终的输出。代码中甚至没有给这个神经网络进行训练，就直接进行了保存。








这样一个神经网络模型文件里是一个什么样的结构呢？是像一般的程序一样，编译完了程度就被转化成了一堆逻辑指令呢？还是继续维持着这样一个模型文件的结构呢？

在运行完上面的代码后，在当前路径下应该多了四个文件，checkpoint，tfmodel.index， tfmodel.meta， tfmodel.data-00000-of-00001，如果没有的话请重新运行文件生成这样的文件。这样四个文件里面保存了什么呢？按照官方文档的解释，meta文件保存了序列化后的计算图，index文件则保存了数据文件的索引，包括变量名等等，data文件是保存了类似于变量值这样的数据的文件，checkpoint记录了最新的模型文件的名称或者序号。什么是计算图呢？直接用图形来做说明吧，

<img src="../Images/13/graph.png" width="500" />

上面的计算图就描述了一个将两个数相乘之后输出的计算过程。模型文件中的计算图描述的也是一个计算过程，不过要比这种简单的过程要复杂很多。

怎么查看一个模型文件中的内容呢？这里要使用[Tools for AI](https://visualstudio.microsoft.com/zh-hans/downloads/ai-tools-vs/?rr=https%3A%2F%2Fwww.msra.cn%2Fzh-cn%2Fnews%2Ffeatures%2Ftools-for-ai)工具里查看模型的功能了，

<img src="../Images/13/AItools.PNG" width="500" ch="500" />

点击view Model按钮，会弹出来这样一个窗口

<img src="../Images/13/netron.PNG" width="500" ch="500" />

选择Open Model，选择我们之前生成的那个简单的模型文件，稍等片刻，会看到这样一张截图：

<img src="../Images/13/model.PNG" width="500" ch="500" />

哇，我不是只写了一个卷积层吗？为什么会多出来这么多东西？

下面呢，让我们来仔细分析下这张图的成分

首先看右半部分，

<img src="../Images/13/graphpart.PNG" width="500" ch="500" />

每个方框是不是很眼熟？conv2D就是我们执行卷积操作的部分，按照箭头标示的数据流走向，经过卷积层处理的数据会进入BiasAdd部分，加上偏置，之后进入Relu部分进行relu操作，经过relu的数据会进行输出。这也就是我们在tensorflow代码中显示构建的部分。

下面我们从各个结点单独入手进行分析。

以卷积层的卷积核这样一个参数结点为例，

<img src="../Images/13/variableNode.PNG" width="500" />

从右侧窗口看到这个变量的尺寸是[5, 5, 3, 8]，正是我们初始化所预期的一个大小。那这个结点有4个和其他结点的联系，我们来逐个看一看。

首先是和左上侧结点之间的联系，

<img src="../Images/13/trunc.PNG" width="400" ch="1176" />

这一条支路上的联系对应的是代码中

```python
conv1_weights = tf.Variable(
      tf.truncated_normal([5, 5, 3, 8],  # 5x5 filter, depth 8.
                          stddev=0.1,
                          seed=SEED))
```

这样的生成一个截断的正态分布的初始化过程。也许有人会好奇这个初始化不是就一步吗？为什么这里会有四个结点进行这样一个过程呢？

分别来看看各个节点的作用吧。这里将依次展示四个结点的性质描述

<img src="../Images/13/trunc1.PNG" width="400" ch="505" />

这是第一个结点的性质描述，该结点的功能也就是生成一个标准的截断的正态分布，也就是标准差是1，平均值是0的标准正态分布。

<img src="../Images/13/trunc2.PNG" width="400" ch="525" />

这是乘法结点的性质描述，看这个结点的两个输入，一个是根据上一个结点输出的正态分布结果，另一个输入就是我们在代码中规定的标准差了，这个结点的作用就是将标准化的正态分布的标准差改变成我们在代码中期望的标准差。

<img src="../Images/13/trunc3.PNG" width="400" ch="500" />

这个结点是一个执行加法操作的结点。在我们对卷积核使用截断的正态分布进行初始化的过程中，我们可以给出期望的两个参数，分别是用于初始化的正太分布的标准差和均值。在上一个乘法结点中，我们对所生成的标准分布的标准差进行了修改，也就是说，输入这个加法结点的是一个标准差是所期望的标准差，但是均值是零的一个正态分布。在加法结点中，我们采取对数据加上所期望的均值的方法将用于初始化的正态分布由标准正态分布转化成一个标准差是输入的stddev参数规定的标准差，均值是输入的mean参数规定的均值的一个正态分布。

<img src="../Images/13/trunc4.PNG" width="400" ch="500" />

在前三步结点的操作中，我们只是生成了这样一个用于初始化的标准正态分布的有关数据，还没有把这个正态分布的值和我们要初始化的卷积核联系起来。这个结点的作用就是建立了这样的一个联系，将初始化操作得到的值赋给卷积核结点。

再看最右边的连接路径

<img src="../Images/13/convkernel.PNG" width="400" ch="526" />

在这部分的计算图中，data结点就是我们在代码中声明的输入结点，Identity结点的作用是将我们的输入tensor进行一侧复制，将复制的结果传入conv2D结点进行卷积计算操作。

也就是说，这一部分就是我们预期的在前向传播中进行的操作的步骤。

那么另外两条路径的作用是什么呢？

再看我们之前的代码，建立模型的部分已经在计算图中体现了，对参数进行初始化的步骤也在最左边的连接中进行过了，还有哪个部分没有讲到呢？

还剩下的部分也就是我们在计算图中剩余的部分，对模型的存储操作了。不过，存储的目的是为了之后能够将模型从新导入代码文件中进行直接的使用，也就是说，虽然我们在代码中只体现了存储的部分，但是tensorlfow这个框架会自动的帮我们补全模型重载需要的操作，这一部分也会体现在计算图中。

而这一个保存，一个重载，也就是剩下的两条连接所对应的内容了。

<img src="../Images/13/saveRestore.PNG" width="500" />

我们之前说，在index文件中保存的是数据文件的索引，是一张表，这样的表里存放了什么呢？从这张计算图中看，在saveV2这样一个结点中，保存了变量的名称，由这个模型的名字，也就是在这份代码中的函数名称"tfmodel"加上变量自己的名称构成一个全局的变量名，保证不会出现重复的tensor名称。之后会存储的是这个tensor的大小，也就是shape_and_slices这个域中的内容，再之后保存的就会是这个tensor本身的值。

restore的过程是一个逆过程。程序会根据tensor的名称和对应的尺寸，从存下的文件中读取对应的tensor的值，经过一个赋值的assign结点，将保存下来的具体数值再重新放入对应的变量中，在目前这个例子中，也就是卷积核这个变量中。

另外一个variable结点对应的连接与我们上面所述的结点完全相似，大家可以自己动手来把这个结点的连接分析出来！

### 阶段小结

从上面的对模型推导过程和对框架输出模型的分析，我们看到，在模型保存过程中，真正需要注意的是，对数据处理过程的记录（也就是计算图）和在这个处理过程中需要用到的参数的记录（计算图中各个计算结点需要用到的参数）。