Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

（未完待续）

# 再谈训练集，验证集，测试集

木头：老师，第就章时您说过测试集的事儿，当时没什么概念，这次果然就用上了。这三个的英文是Training Set, Validation Set, Test Set，对吧？

铁柱：对！其中验证集Validation Set也可以叫开发集（Developer Set）。因为这次我们的手写字符的训练结果，无法用图形化的形式展示其准确程度，所以必须用独立的测试集来测试。注意，不能用测试集的数据去训练哦，否则就违背了神经网络训练的基本准则，自欺欺人了。

木头：啊！这么严重？

铁柱：在实际的生产环境中，Training Set用于训练模型，Validation Set用来统计评估指标，调节参数，选择算法，Test Set最后整体评估模型性能。

木头：那我们在这一章中，为什么没有Validation Set呢？

铁柱：因为我们的这个手写数字识别的问题，模型训练比较简单，一个两层的网络就足够了，参数也没有多少，所以中间的调整训练的过程并不复杂，所以没必要用验证集来帮忙，反而会增加工作复杂度。在一些复杂的模型中，模型可能只对训练数据有效，对验证数据就效果很差，你就根本没必要去用测试集做测试了。

木头：那具体如何使用Validation Set呢？

铁柱：在传统的机器学习中，比如一个SVM，我们经常用交叉验证(Cross Validation)的方法，比如把数据分成10份，V1-V10，其中V1-V9用来训练，V10用来验证。然后用V2-V10做训练，V1做验证......如此我们可以做10次训练和验证，大大增加了模型的可靠性。

木头：好办法！验证集也可以做训练，训练集数据也可以做验证，当样本很少时，这个很有用。那么深度学习中的用法是什么呢？

铁柱：比如在神经网络中，训练时到底迭代多少次停止呢？或者我们设置学习率为多少何时呢？或者用几个中间层，以及每个中间层用几个神经元呢？这些都可以用验证集来解决。在咱们前面的学习中，一般使用diff_loss < 1e-10做为迭代终止条件，虽然在绝大多数情况下可行，但不是绝对的，不能保证随机梯度下降算法陷入局部最优解。此时，我们可以用验证集来验证一下准确率，假设只有90%的的准确率，那可能确实是局部最优解。这样我们可以继续迭代，寻找全局最优解。

木头：那么这三者的比例关系如何调配呢？

铁柱：看下图吧。在传统的机器学习中，三者可以是6:2:2。在深度学习中，一般要求样本数据量很大，所以可以给训练集更多的数据，比如8:1:1。开发集，顾名思义，只给开发人员使用，他们看不到测试集。好比“公检法”三者的关系，公安局（训练集）负责抓坏人（我们抓到了一个模型！），检察院（验证集）负责诉讼（我们认为这个模型还不错！），法院（测试集）负责审判坏人（大锤子一敲：这个模型不好，重新去抓！），

<img src="./Images/10/dataset.jpg"/>

木头：（捂嘴狂笑）老师您以前是...公检法岗位的...？（继续松枝乱颤）

铁柱：笑什么笑！（恨不得真有个大锤子敲木头脑袋一下）讲真，我们还没有学习得到正则化一类的知识，那些参数都是靠验证集来确定的，并不是训练出来的。

木头：（一脸懵）肿么弄？

铁柱：正则化分为L1/L2两种，实际上是在误差函数后面增加一个项，以避免过度拟合。这个项里面有个参数，我们并不知道设置为多少合适，而是从0.01到1之间用验证集去试验训练效果。

木头：那如何知道是过拟合了呢？

铁柱：......啊，问题越来越深了，这个咱们后面遇到时再讲吧。

# 再谈数据归一化

木头：在第5/6两章中，我们已经用了数据归一化大法，否则有可能根本训练不出结果，如第5章中的房价数据，或者训练速度很慢，如第6章中的污染物分类。在这一章中，我看到我们使用了不一样的归一化数据处理方法，这是为什么呢？

下面这段代码是第5/6两章中使用的数据归一化方法：
```Python
def NormalizeData(X):
    X_NEW = np.zeros(X.shape)
    # get number of features
    n = X.shape[0]
    for i in range(n):
        x_row = X[i,:]
        x_max = np.max(x_row)
        x_min = np.min(x_row)
        if x_max != x_min:
            x_new = (x_row - x_min)/(x_max-x_min)
            X_NEW[i,:] = x_new
    return X_NEW
```

下面这段代码是第10章中使用的数据归一化方法：
```Python
def NormalizeData(X):
    X_NEW = np.zeros(X.shape)
    x_max = np.max(X)
    x_min = np.min(X)
    X_NEW = (X - x_min)/(x_max-x_min)
    return X_NEW
```

铁柱：眼神儿不错啊！很细心！你可以先把第5/6两章中的样本数据拿来咱们一起看看。

木头：好嘞！...（5分钟后）...我把样本数据列在下面了：

|样本序号|1|2|3|4|...|1000|
|---|---|----|---|--|--|--|
|朝向|1|4|2|4|...|2|
|地理位置|3|2|6|3|...|3|
|面积|96|100|54|72|...|69|
|价格|434|500|321|482|...|410|

|样本序号|1|2|3|4|...|200|
|---|---|----|---|--|--|--|
|温度|0|13|2|24|...|8|
|湿度|55|14|46|58|...|78|
|污染物|0|2|1|2|...|0|

铁柱：好，你看看这两个样本与手写体识别的样本比较，有什么区别？

木头：（抓耳挠腮5分钟）... 怎么看啊？没法比较啊？

铁柱：（喝了口绿茶）提示一下，主要看数值方面。

木头：（喝了口二锅头）... 啊！有点儿明白了，这两个数据，样本的每个特征值的取值范围与其它特征值都不同，比如房屋朝向取值[1,4]，地理位置取值[2,6]，面积取值[50,140]。污染物的温度取值[0,40]，湿度取值[0,100]。

铁柱：嗯嗯！那么MNIST的数据呢？

木头：MNIST的数据全是[0,255]，我们是这样排列的：

|样本序号|1|2|3|4|...|60000|
|---|---|----|---|--|--|--|
|点1|0|0|0|0|...|0|
|点2|0|0|12|0|...|59|
|点3|0|0|56|253|...|98|
|点m|0|23|148|0|...|0|
|点784|0|0|0|0|...|0|

也就是说，数据虽然分成多个特征值（行），但是每个特征的取值范围实际上都是[0,255]。

铁柱：对！咱们在第5/6章中的归一化代码，输入是整个表格X，先得到X.shape[0]，也就是特征值的数量，然后逐行做归一化，也就是说房屋朝向和地理位置的归一化范围并不相同。而第10章中，所有数据全是[0,255]，如果逐行归一，很可能出现这种情况：

- 有一行的数据是：(2,23,148,...3,45)，最大值是148，最小值是2，那么就会把2归一为0，把148归一为1。
- 而在另外一行的数据可能是：(0,3,248,...13,4)，会把0归一为0，把248归一为1。

这样的话，这两行的数据就不可比了，也就是说，本来都是点阵数据，表示灰度的，却被人为地改变了数据的相对值。

木头：哦！对！把图像的二维点阵处理成一维的特征值，是为了计算方便，并不是要改变点阵本身的数值特性。但是，老师，如果不小心这样做了，会有什么问题吗？

铁柱：对于这个手写识别的例子来说，没有多大影响，因为每个特征之间没什么联系，值的相对变化不会影响训练结果。对于别的例子就不好说了，以后咱们遇到时再分析。


|flag = 1, 随机初始化|flag = 2, Xavier初始化|
|---|---|
|rate=9040 / 10000 = 0.9040%|rate=9407 / 10000 = 0.9407%|
|<img src="./Images/10/Init-Random.png">|<img src="./Images/10/Init-Xavier.png">|

