Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

在第十章中，我们用一个两层的神经网络，实现了异或逻辑。这次我们尝试一个新的数据集，来测试一下mini框架对二分类任务的支持程度。

# 数据来源

我们用一个真实的数据级来实现一个二分类任务：收入调查。此数据集是从1994 Census数据库中提取的，用于预测收入是否可以大于$50K/年。


以下是原始数据集的链接：
https://archive.ics.uci.edu/ml/datasets/Census+Income

Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science. 

感谢数据集的提供者：

Ronny Kohavi and Barry Becker 
Data Mining and Visualization 
Silicon Graphics. 
e-mail: ronnyk '@' sgi.com for questions. 

# 数据字段解读

标签值：>50K，<=50K。

属性字段：

- age: continuous. 
- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. 
- fnlwgt: continuous. 
- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. 
- education-num: continuous. 
- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. 
- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. 
- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. 
race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. 
- sex: Female, Male. 
- capital-gain: continuous. 
- capital-loss: continuous. 
- hours-per-week: continuous. 
- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, H



数据部分的code，基本是通用的。Normalize方法有一些参数，可以控制是否归一化X值、归一化Y值、是否把标签转换成One-hot形式。对于本例，X和Y值已经处于[0,1]空间了，不需要归一化，所以是两个False。由于是回归任务，所以也不需要转One-hot编码。

## 可视化结果

```Python
def ShowResult(net, dataReader, title):
    # draw train data
    plt.plot(dataReader.X[0,:], dataReader.Y[0,:], '.', c='b')
    # create and draw visualized validation data
    TX = np.linspace(0,1,100).reshape(1,100)
    TY = net.inference(TX)
    plt.plot(TX, TY, 'x', c='r')
    plt.title(title)
    plt.show()
```

## 搭建模型

```Python
if __name__ == '__main__':
    dataReader = LoadData()
    num_input = 1
    num_hidden1 = 4
    num_output = 1

    max_epoch = 10000
    batch_size = 10
    learning_rate = 0.5
    eps = 0.001

    params = CParameters(learning_rate, max_epoch, batch_size, eps,
                        LossFunctionName.MSE, 
                        InitialMethod.Xavier, 
                        OptimizerName.SGD)

    net = NeuralNet(params)
    fc1 = FcLayer(num_input, num_hidden1, params)
    net.add_layer(fc1, "fc1")
    sigmoid1 = ActivatorLayer(Sigmoid())
    net.add_layer(sigmoid1, "sigmoid1")
    fc2 = FcLayer(num_hidden1, num_output, params)
    net.add_layer(fc2, "fc2")

    net.train(dataReader, checkpoint=10, need_test=False)
    net.ShowLossHistory()
    
    ShowResult(net, dataReader, params.toString())
```

1. 先构造一个参数集合CParameters，包括：
   1. 学习率
   2. 最大epoch
   3. 批大小
   4. eps停止条件
   5. 损失函数形态(MSE均方差)
   6. 初始化方法(default为Xavier)
   7. 优化器选择default为(SGD)
2. 构造网络NeuralNet，传入参数
3. 构造第一个FC层，指定输入样本特征数量和输出（num_hidden1）神经元个数值，及Sigmoid激活函数
4. 构造第二个FC层，指定输入和输出尺寸，因为是回归任务，所以没有分类函数
5. 开始训练，并传入DataReader实例

net.train()函数是一个阻塞函数，只有当训练完毕后才返回。



# 代码位置

ch14, Level2
