Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  
# 多分类结果可视化

木头：老师，我还是和二分类同样的问题，如何直观地理解多分类的结果？

铁柱：这个比二分类要复杂一些。我们先把原始数据显示出来。

```Python
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import math
from BaseClassification import *
from level3_MultipleClassification import *

def ShowData(X,Y):
    for i in range(X.shape[1]):
        if Y[0,i] == 1:
            plt.plot(X[0,i], X[1,i], '.', c='r')
        elif Y[0,i] == 2:
            plt.plot(X[0,i], X[1,i], 'x', c='g')
        elif Y[0,i] == 3:
            plt.plot(X[0,i], X[1,i], '^', c='b')
        # end if
    # end for
    plt.show()
```

会画出下面这张图：

<img src=".\Images\6\MultipleClassifierData.png">


下面的数据是神经网络训练出的结果：

```Python
epoch=99, iteration=115, loss=0.065409
W= [[-3.53207999 11.31094203]
 [-7.2749168  -7.00354565]
 [10.80699679 -4.30739638]]
B= [[-4.30753322]
 [ 8.51783018]
 [-4.21029697]]
Probility= [[1.06821435e-04 2.42947816e-01 4.84891526e-01 6.73531781e-01]
 [9.64663416e-01 1.02809223e-01 4.51424722e-01 3.26269149e-01]
 [3.52297621e-02 6.54242961e-01 6.36837515e-02 1.99069931e-04]]
Result= [2 3 1 1]
```

前面我们学习过了，多分类有几种方式：
- 一对一
- 一对多
- 多对多

那么神经网络是哪种方式呢？你猜猜。

木头：从Softmax的函数特性看，它每次取一个最大值，所以我觉得它是一对多的方式。

铁柱：哈哈哈哈（狂笑）....（木头一头雾水）......仔细分析一下神经网络的计算过程。

$$Z = W \cdot X+B$$

实际上是以下计算的组合：

$$Z1 = W1 \cdot X + B1=w_{11} \cdot x_1 + w_{12} \cdot x_2 + b_1$$

$$Z2 = W2 \cdot X + B2=w_{21} \cdot x_1 + w_{22} \cdot x_2 + b_2 $$

$$Z3 = W3 \cdot X + B3=w_{31} \cdot x_1 + w_{32} \cdot x_2 + b_3$$

如何确定(Z1|Z2)之间的边界呢？那只要令Z1=Z2就行了......

因为:

$$Z1=Z2$$

所以：

$$w_{11} \cdot x_1 + w_{12} \cdot x_2 + b_1 = w_{21} \cdot x_1 + w_{22} \cdot x_2 + b_2 $$
$$w_{12} \cdot x_2 - w_{22} \cdot x_2  = -w_{11} \cdot x_1 + w_{21} \cdot x_1 +  b_2 - b_1$$
$$(w_{12} - w_{22}) \cdot x_2  = (w_{21}-w_{11}) \cdot x_1  +  (b_2 - b_1)$$
$$x_2  = {w_{21}-w_{11} \over w_{12} - w_{22}} \cdot x_1  +  {b_2 - b_1 \over w_{12} - w_{22}}=w_{12} \cdot x_1 + b_{12} \tag{公式一,1|2边界}$$

然后再同样地处理Z1=Z3和Z2=Z3，得到下述公式：

$$x_2 = {w_{31}-w_{21} \over w_{22} - w_{32}} \cdot x_1  +  {b_3 - b_2 \over w_{22} - w_{32}}=w_{23} \cdot x_1 + b_{23} \tag{公式二,2|3边界}$$

$$x_2  = {w_{31}-w_{11} \over w_{12} - w_{32}} \cdot x_1  +  {b_3- b_1 \over w_{12} - w_{32}}=w_{13} \cdot x_1 + b_{13} \tag{公式三,1|3边界}$$

木头：变成code......

```Python
def ShowResult(X,Y,W,B,xt):
    ......
    # 公式一
    b12 = (B[1,0] - B[0,0])/(W[0,1] - W[1,1])
    w12 = (W[1,0] - W[0,0])/(W[0,1] - W[1,1])
    # 公式二
    b23 = (B[2,0] - B[1,0])/(W[1,1] - W[2,1])
    w23 = (W[2,0] - W[1,0])/(W[1,1] - W[2,1])
    # 公式三
    b13 = (B[2,0] - B[0,0])/(W[0,1] - W[2,1])
    w13 = (W[2,0] - W[0,0])/(W[0,1] - W[2,1])

    ......
```
以上code只展示了计算三条直线的参数的过程，省略了一些其它功能。

改一下主函数，增加对以上两个函数的调用：

```Python
# 主程序
if __name__ == '__main__':
    # SGD, MiniBatch, FullBatch
    method = "SGD"
    # read data
    XData,YData = ReadData(x_data_name, y_data_name)
    X, X_norm = NormalizeData(XData)
    ShowData(XData, YData)
    num_category = 3
    Y = ToOneHot(YData, num_category)
    W, B = train(method, X, Y, ForwardCalculationBatch, CheckLoss)

    print("W=",W)
    print("B=",B)
    xt = np.array([5,1,7,6,5,6,2,7]).reshape(2,4,order='F')
    a, xt_norm, r = Inference(W,B,X_norm,xt)
    print("Probility=", a)
    print("Result=",r)
    ShowResult(X,YData,W,B,xt_norm)
```

最后可以看到这样的分类结果图（注意，这个结果图和我们在6.6.5中分析的一样，只是红线斜率不同）：

<img src=".\Images\6\multiple_result.png">

【图6.6.2 想象中的一对一方式的分类结果图】

上图中：
- 绿色线是1|2的边界，不考虑第3类
- 蓝色线是1|3的边界，不考虑第2类
- 红色线是2|3的边界，不考虑第1类

我们只看红色的第1类，当要区分1|2和1|3时，神经网络实际是用了两条直线（绿色和蓝色）作为边界，它并没有画出下面这样的线来：

<img src=".\Images\6\OneVsOthers.png">

【图6.6.3 想象中的一对多方式的分类】

上面这张图是我们想象的所谓的一对多的方式，只看红线，它把红点和其它点一次分割成型。而神经网络没有画出这样的线来，这意味着神经网络不是一对多方式吗？而且

事情还没有那么简单！有了图6.6.2，并不意味着它是一对一方式；而没有得到图6.6.3，并不意味着它就不是一对多方式。

木头：嗯...哦...有点儿绕...

铁柱：图6.6.2是我们依靠令Z1=Z2, Z2=Z3, Z3=Z1三个等式得到的，但实际上神经网络的工作方式不是这样的，给定屏幕上任意点，分类器总会给你一个概率，告诉你该点分别属于三个区域的概率，比如：

$$[0.7,0.2,0.1]$$

意为属于第一个区域的概率为0.7，属于后两个区域的概率为0.2与0.1。而Z1=Z2等三个等式，是我们人为地画了三条直线，而实际上，它们不应该是直线，而是线段：

<img src=".\Images\6\multiple_result_true.png">

【图6.6.4 分段线性分类结果】

木头：如何证明这一点呢？

铁柱：代码中还有一个小彩蛋，ShowAreaResult()函数，有兴趣的同学可以自己试一下，放开注释即可以看到下图：

<img src=".\Images\6\multiple_result_area.png">

【图6.6.5】

由于精度较低（我们用了50x50的网格来模拟整个区域），所以看到一些锯齿，不用管它，只看趋势，完全与图6.6.4吻合，所以说明神经网络是用分段线性的方法，来做一对多的分类，而不是像我们想象的图6.6.3那样的单条直线。

代码位置：ch06, Level0, level3, level4

**课后作业**

实现逻辑与门和或门，要求精度为1e-2。即，输出结果与目标值的误差小于1e-2。
