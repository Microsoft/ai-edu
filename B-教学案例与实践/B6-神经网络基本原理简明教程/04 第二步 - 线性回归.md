Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

## <center>第二步</center>

# <center>线性回归</center>

## 摘要

用线性回归作为学习神经网络的起点，是一个非常好的选择，因为线性回归问题本身比较容易理解，在它的基础上，逐步的增加一些新的知识点，会形成一条比较平缓的学习曲线，或者说是迈向神经网络的第一个小台阶。

单层的神经网络，其实就是一个神经元，可以完成一些线性的工作，比如拟合一条直线，这用一个神经元就可以实现。当这个神经元只接收一个输入时，就是单变量线性回归，可以在二维平面上用可视化方法理解。当接收多个变量输入时，叫做多变量线性回归，此时可视化方法理解就比较困难了，通常我们会用变量两两组对的方式来表现。

当变量多于一个时，两个变量的量纲和数值有可能差别很大，这种情况下，我们通常需要对样本特征数据做归一化，然后把数据喂给神经网络进行训练，否则会出现“消化不良”的情况。

从本章开始，有两个人物会出现在一些章节中，以问答方式来引导读者学习知识。

- “铁柱”是一名老师，在神经网络中穿梭多年，挂了满身的蜘蛛网。
- “木头”是一名刚入门者，木头木脑的，有问题经常向铁柱请教。

实际上，木头就是笔者的笔名，文章中的一些问题，都是在笔者学习神经网络时遇到的。而铁柱是各种博客、文章、教程的集合，是木头在学习过程中请教的虚拟人物。
